{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd186a625c194bf58af3ce2dcbe57707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe93f602b357497991ac1ee266936d53",
              "IPY_MODEL_67d3f1a2901c4b09b804bb1e637ed742",
              "IPY_MODEL_4704d3919433489c92fb6026cc022221"
            ],
            "layout": "IPY_MODEL_9392ef75167241668d0c2624c3dc77af"
          }
        },
        "fe93f602b357497991ac1ee266936d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a835167e3e64d048142459890bb2e21",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b92b7b1a694081b3e400ee316e2d9e",
            "value": "Map: 100%"
          }
        },
        "67d3f1a2901c4b09b804bb1e637ed742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c266288792d4235a8f6f250be4062e0",
            "max": 6999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2db25bb132164e7099a902d8a6e1993f",
            "value": 6999
          }
        },
        "4704d3919433489c92fb6026cc022221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f00b022e4794a268cdcff5f982f3b32",
            "placeholder": "​",
            "style": "IPY_MODEL_19ff50a03f1a4b97ae6cd25b0196610b",
            "value": " 6999/6999 [00:02&lt;00:00, 3562.10 examples/s]"
          }
        },
        "9392ef75167241668d0c2624c3dc77af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a835167e3e64d048142459890bb2e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b92b7b1a694081b3e400ee316e2d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c266288792d4235a8f6f250be4062e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db25bb132164e7099a902d8a6e1993f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f00b022e4794a268cdcff5f982f3b32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ff50a03f1a4b97ae6cd25b0196610b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8847145801a4dc1a21d7c09db768274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1688fad51d394761915959d32db5721b",
              "IPY_MODEL_6ecef832ae954f028a3af7da86e68e52",
              "IPY_MODEL_e895c24ff16d4ba2a23e127163121861"
            ],
            "layout": "IPY_MODEL_985539d20ccf41eeb3400b2cfd16b7cb"
          }
        },
        "1688fad51d394761915959d32db5721b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a40293716c4946ab8b6457447712eef1",
            "placeholder": "​",
            "style": "IPY_MODEL_3efbf6cacfca4246b78b8cfe1955976e",
            "value": "Map: 100%"
          }
        },
        "6ecef832ae954f028a3af7da86e68e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edcef05a1511480a8c77de0a78a12161",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07f0fc6ab4f841e090c8d528eaec76ae",
            "value": 1000
          }
        },
        "e895c24ff16d4ba2a23e127163121861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae56a6cd87fc4b8ca9e434f39c8f1638",
            "placeholder": "​",
            "style": "IPY_MODEL_6f2f0622693a4b97b28b7b4c3799979b",
            "value": " 1000/1000 [00:00&lt;00:00, 4136.53 examples/s]"
          }
        },
        "985539d20ccf41eeb3400b2cfd16b7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40293716c4946ab8b6457447712eef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3efbf6cacfca4246b78b8cfe1955976e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edcef05a1511480a8c77de0a78a12161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f0fc6ab4f841e090c8d528eaec76ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae56a6cd87fc4b8ca9e434f39c8f1638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f2f0622693a4b97b28b7b4c3799979b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dfcabab9bc44fc8bb575b0dc3a8fd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83b1d611456d4146863779e86bd72e13",
              "IPY_MODEL_726fb502d28c406c91dc938929d168cc",
              "IPY_MODEL_35d9b35179614a14886125675b0a59f0"
            ],
            "layout": "IPY_MODEL_4148b44add8444c29eeab43d367fb9c5"
          }
        },
        "83b1d611456d4146863779e86bd72e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53a4da0f26ff4df781fdf70814ab4748",
            "placeholder": "​",
            "style": "IPY_MODEL_d5df04790cc64d398f9ccfabfc7355fb",
            "value": "Map: 100%"
          }
        },
        "726fb502d28c406c91dc938929d168cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eecbdef76ea42d59e9f6e3833eb5024",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87ee45f8b3de4ce3a91073e76e9ed5d8",
            "value": 2000
          }
        },
        "35d9b35179614a14886125675b0a59f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b522428659d64ea6ae965a45813293f3",
            "placeholder": "​",
            "style": "IPY_MODEL_0a63e213a6474d7f9d30d29bad4da09d",
            "value": " 2000/2000 [00:00&lt;00:00, 4736.43 examples/s]"
          }
        },
        "4148b44add8444c29eeab43d367fb9c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a4da0f26ff4df781fdf70814ab4748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5df04790cc64d398f9ccfabfc7355fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eecbdef76ea42d59e9f6e3833eb5024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ee45f8b3de4ce3a91073e76e9ed5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b522428659d64ea6ae965a45813293f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a63e213a6474d7f9d30d29bad4da09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31fd40bc89394cc699462dba7d1df588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3d53f02b7974f879d7ef27f17809ef0",
              "IPY_MODEL_4b2e9bcc7fc5478e84641d0827511278",
              "IPY_MODEL_ca375fd66da24c1582d6fe079ab55c88"
            ],
            "layout": "IPY_MODEL_66b21978572d4ec19b935ea83db0f9cc"
          }
        },
        "f3d53f02b7974f879d7ef27f17809ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c879de03f894a4dbd35625122915313",
            "placeholder": "​",
            "style": "IPY_MODEL_dbea01ac9fa444d6bffbc6bf25af7a4f",
            "value": "Batches: 100%"
          }
        },
        "4b2e9bcc7fc5478e84641d0827511278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa60558605694c6cbfdb058a5a44f1e9",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6f5da1882724d86bf9642278ce7153c",
            "value": 313
          }
        },
        "ca375fd66da24c1582d6fe079ab55c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f29db02b509f41cf976b471e24a8d335",
            "placeholder": "​",
            "style": "IPY_MODEL_ae48bb80e44849feb3fdd0ee1388bd05",
            "value": " 313/313 [00:06&lt;00:00, 93.66it/s]"
          }
        },
        "66b21978572d4ec19b935ea83db0f9cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c879de03f894a4dbd35625122915313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbea01ac9fa444d6bffbc6bf25af7a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa60558605694c6cbfdb058a5a44f1e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f5da1882724d86bf9642278ce7153c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f29db02b509f41cf976b471e24a8d335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae48bb80e44849feb3fdd0ee1388bd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# CLIMATE SENTIMENT AI - Version avec splits train/val/test et graphiques losses\n",
        "# Split: 70% train / 10% validation / 20% test\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "umegBqNOwiIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit wandb torch transformers peft faiss-cpu sentence-transformers rouge-score plotly pandas tqdm scikit-learn matplotlib numpy==1.26.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZHwKmzj0un5",
        "outputId": "8429b968-e768-4c02-dfab-7b8a90e4701b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.47.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0.post1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.7.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb, os, json, time, torch, numpy as np, pandas as pd, streamlit as st\n",
        "import random, tqdm\n",
        "from datasets import Dataset\n",
        "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "                          Trainer, TrainingArguments, pipeline, TrainerCallback)\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import plotly.graph_objects as go\n",
        "from rouge_score import rouge_scorer\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "WlzcuibjwhIK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ====================================================================\n",
        "# 1. CONFIGURATION & SETUP\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "2Vv1Fv_Wwn0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration W&B\n",
        "WANDB_PROJECT = \"climate-sentiment-lora-train-val-test\"\n",
        "if not os.getenv(\"WANDB_API_KEY\"):\n",
        "    st.error(\"⚠️ WANDB_API_KEY manquant ! Définissez-le dans vos variables d'environnement.\")\n",
        "    st.stop()\n",
        "\n",
        "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
        "\n",
        "# Configuration modèle - T5 pour classification + génération unifiée\n",
        "MODEL_NAME = \"t5-small\"  # Modèle seq2seq pour tâches unifiées\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"🔧 Configuration: Modèle={MODEL_NAME}, Device={DEVICE}\")\n",
        "\n",
        "# Optimisations CPU\n",
        "if DEVICE == \"cpu\":\n",
        "    torch.set_num_threads(4)\n",
        "    print(\"🚀 Optimisations CPU activées\")\n",
        "\n",
        "# Variables globales pour stocker les métriques d'entraînement\n",
        "training_logs = {\n",
        "    \"train_loss\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"test_loss\": [],\n",
        "    \"epochs\": [],\n",
        "    \"steps\": []\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkbnz_OxwnsZ",
        "outputId": "bbbc9003-0ccb-4a2e-b41f-6b2c6e4e76cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-25 14:24:45.860 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:46.408 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-07-25 14:24:46.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:46.413 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:46.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk_benyahia\u001b[0m (\u001b[33mk_benyahia-pstb\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Configuration: Modèle=t5-small, Device=cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 2. CALLBACK POUR TRACKING DES LOSSES\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "jmjYTO3uwto3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LossTrackingCallback(TrainerCallback):\n",
        "    \"\"\"Callback personnalisé pour tracker les losses train/val/test.\"\"\"\n",
        "\n",
        "    def __init__(self, test_dataset, tokenizer):\n",
        "        self.test_dataset = test_dataset\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        \"\"\"Appelé à chaque log pendant l'entraînement.\"\"\"\n",
        "        if logs:\n",
        "            current_step = state.global_step\n",
        "\n",
        "            # Train loss\n",
        "            if \"loss\" in logs:\n",
        "                training_logs[\"train_loss\"].append(logs[\"loss\"])\n",
        "                training_logs[\"steps\"].append(current_step)\n",
        "\n",
        "            # Validation loss\n",
        "            if \"eval_loss\" in logs:\n",
        "                training_logs[\"val_loss\"].append(logs[\"eval_loss\"])\n",
        "\n",
        "                # Calculer test loss si on a des métriques d'évaluation\n",
        "                if hasattr(state, 'model'):\n",
        "                    test_loss = self._compute_test_loss(state.model)\n",
        "                    training_logs[\"test_loss\"].append(test_loss)\n",
        "\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        \"\"\"Appelé à la fin de chaque époque.\"\"\"\n",
        "        training_logs[\"epochs\"].append(state.epoch)\n",
        "\n",
        "    def _compute_test_loss(self, model):\n",
        "        \"\"\"Calcule la loss sur le test set.\"\"\"\n",
        "        try:\n",
        "            model.eval()\n",
        "            total_loss = 0\n",
        "            num_batches = 0\n",
        "\n",
        "            # Échantillonner quelques exemples du test set pour la loss\n",
        "            test_samples = random.sample(list(self.test_dataset), min(50, len(self.test_dataset)))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for sample in test_samples:\n",
        "                    inputs = {k: v.unsqueeze(0).to(model.device) for k, v in sample.items()\n",
        "                             if k in ['input_ids', 'attention_mask', 'labels']}\n",
        "\n",
        "                    outputs = model(**inputs)\n",
        "                    total_loss += outputs.loss.item()\n",
        "                    num_batches += 1\n",
        "\n",
        "            return total_loss / num_batches if num_batches > 0 else 0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur calcul test loss: {e}\")\n",
        "            return 0\n"
      ],
      "metadata": {
        "id": "0DqC-wTOwthC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ====================================================================\n",
        "# 3. FONCTIONS DE VÉRIFICATION (SANITY CHECKS)\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "QFu2NAq2w5aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sanity_check_dataset(ds, split_name, n=3):\n",
        "    \"\"\"Affiche quelques exemples + vérifie présence des colonnes nécessaires.\"\"\"\n",
        "    required_cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "    for col in required_cols:\n",
        "        assert col in ds.column_names, f\"Colonne {col} manquante dans {split_name}!\"\n",
        "\n",
        "    print(f\"📊 Dataset {split_name}: {len(ds)} échantillons\")\n",
        "    for i in range(min(n, len(ds))):\n",
        "        print(f\"Exemple {i}: {ds[i]}\")\n",
        "    print(f\"✅ Dataset {split_name} validé\")\n",
        "\n",
        "def sanity_check_model(model, tokenizer, text=\"Climate change is serious\"):\n",
        "    \"\"\"Test forward pass rapide.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "        loss = outputs.loss\n",
        "\n",
        "    print(f\"✅ Forward pass OK - Loss: {loss:.4f}\")\n",
        "\n",
        "def sanity_check_retrieval(encoder, index, corpus, query=\"climate change\"):\n",
        "    \"\"\"Test du système de retrieval.\"\"\"\n",
        "    if len(corpus) == 0:\n",
        "        print(\"❌ Corpus vide\")\n",
        "        return\n",
        "\n",
        "    emb = encoder.encode([query])\n",
        "    scores, ids = index.search(np.array(emb).astype(\"float32\"), min(2, len(corpus)))\n",
        "\n",
        "    print(f\"✅ Retrieval OK - Trouvé {len(ids[0])} documents\")\n",
        "    for i, (score, doc_id) in enumerate(zip(scores[0], ids[0])):\n",
        "        if doc_id < len(corpus):\n",
        "            print(f\"  {i+1}. Score: {score:.3f} - {corpus[doc_id][:100]}...\")"
      ],
      "metadata": {
        "id": "xAseq34Dw5RY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ====================================================================\n",
        "# 4. CHARGEMENT ET PRÉPARATION DES DONNÉES\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "t28cuJAIxAuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@st.cache_data\n",
        "def load_reddit_data(file_path='sentiment_enriched_data_batch.csv', n=10_000):\n",
        "    \"\"\"\n",
        "    Charge et nettoie le dataset Reddit climatique.\n",
        "    Split: 70% train / 10% validation / 20% test\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, quoting=3, on_bad_lines='skip', engine='python') # Ignore quotes and skip bad lines\n",
        "    except FileNotFoundError:\n",
        "        st.error(f\"❌ Fichier {file_path} non trouvé!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Nettoyage\n",
        "    df = df.dropna(subset=['comment_sentiment', 'post_title', 'self_text'])\n",
        "\n",
        "    # Mapping sentiment vers labels numériques\n",
        "    sentiment2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
        "    df[\"label\"] = df[\"comment_sentiment\"].map(sentiment2id)\n",
        "    df = df.dropna(subset=['label'])\n",
        "\n",
        "    # Création du texte combiné\n",
        "    df[\"text\"] = (df[\"post_title\"].fillna('') + ' ' + df[\"self_text\"].fillna('')).str.strip()\n",
        "\n",
        "    # Échantillonnage stratifié\n",
        "    df_sampled = df.groupby('label').apply(\n",
        "        lambda x: x.sample(min(len(x), n//3), random_state=42)\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    print(f\"📊 Dataset total: {len(df_sampled)} échantillons\")\n",
        "    print(\"Distribution des classes:\")\n",
        "    print(df_sampled['label'].value_counts().sort_index())\n",
        "\n",
        "    return df_sampled[[\"text\", \"label\", \"subreddit\"]].reset_index(drop=True)\n",
        "\n",
        "def create_train_val_test_splits(df, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Crée les splits train/validation/test avec stratification.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame source\n",
        "        train_ratio: Proportion pour train (0.7 = 70%)\n",
        "        val_ratio: Proportion pour validation (0.1 = 10%)\n",
        "        test_ratio: Proportion pour test (0.2 = 20%)\n",
        "\n",
        "    Returns:\n",
        "        dict avec les 3 splits\n",
        "    \"\"\"\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Les ratios doivent sommer à 1.0\"\n",
        "\n",
        "    # Première division: 80% (train+val) / 20% (test)\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    train_val_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=test_ratio,\n",
        "        random_state=42,\n",
        "        stratify=df['label']\n",
        "    )\n",
        "\n",
        "    # Deuxième division: 70% train / 10% val (sur les 80% restants)\n",
        "    val_ratio_adjusted = val_ratio / (train_ratio + val_ratio)  # 0.1/0.8 = 0.125\n",
        "\n",
        "    train_df, val_df = train_test_split(\n",
        "        train_val_df,\n",
        "        test_size=val_ratio_adjusted,\n",
        "        random_state=42,\n",
        "        stratify=train_val_df['label']\n",
        "    )\n",
        "\n",
        "    print(f\"📊 Splits créés:\")\n",
        "    print(f\"  - Train: {len(train_df)} échantillons ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "    print(f\"  - Validation: {len(val_df)} échantillons ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "    print(f\"  - Test: {len(test_df)} échantillons ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "    # Vérifier distribution des classes\n",
        "    print(\"\\n📊 Distribution par split:\")\n",
        "    for split_name, split_df in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
        "        dist = split_df['label'].value_counts(normalize=True).sort_index()\n",
        "        print(f\"  {split_name}: {dict(dist)}\")\n",
        "\n",
        "    return {\n",
        "        \"train\": train_df.reset_index(drop=True),\n",
        "        \"validation\": val_df.reset_index(drop=True),\n",
        "        \"test\": test_df.reset_index(drop=True)\n",
        "    }\n",
        "\n",
        "# Chargement des données\n",
        "reddit_df = load_reddit_data()\n",
        "\n",
        "if len(reddit_df) == 0:\n",
        "    st.error(\"❌ Impossible de charger les données\")\n",
        "    st.stop()\n",
        "\n",
        "# Création des splits\n",
        "data_splits = create_train_val_test_splits(reddit_df)\n",
        "\n",
        "# Upload vers W&B\n",
        "def upload_dataset_to_wandb():\n",
        "    \"\"\"Upload du dataset avec splits vers W&B Artifacts.\"\"\"\n",
        "    with wandb.init(project=WANDB_PROJECT, job_type=\"dataset-upload\"):\n",
        "        artifact = wandb.Artifact(\"reddit-climate-train-val-test\", type=\"dataset\")\n",
        "\n",
        "        # Sauvegarder chaque split\n",
        "        for split_name, split_df in data_splits.items():\n",
        "            filename = f\"{split_name}_data.csv\"\n",
        "            split_df.to_csv(filename, index=False)\n",
        "            artifact.add_file(filename)\n",
        "\n",
        "        # Métadonnées\n",
        "        metadata = {\n",
        "            \"total_samples\": len(reddit_df),\n",
        "            \"train_samples\": len(data_splits[\"train\"]),\n",
        "            \"val_samples\": len(data_splits[\"validation\"]),\n",
        "            \"test_samples\": len(data_splits[\"test\"]),\n",
        "            \"classes\": reddit_df['label'].value_counts().to_dict(),\n",
        "            \"split_ratios\": {\"train\": 0.7, \"val\": 0.1, \"test\": 0.2}\n",
        "        }\n",
        "        artifact.metadata = metadata\n",
        "\n",
        "        wandb.log_artifact(artifact)\n",
        "        print(\"✅ Dataset avec splits uploadé vers W&B\")\n",
        "\n",
        "upload_dataset_to_wandb()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "mYW8un3WxAj7",
        "outputId": "159bd458-5ebc-40ae-88bf-597eda2f8d69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-25 14:24:47.703 No runtime found, using MemoryCacheStorageManager\n",
            "2025-07-25 14:24:47.706 No runtime found, using MemoryCacheStorageManager\n",
            "2025-07-25 14:24:47.707 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:47.708 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:47.708 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:47.709 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:48.218 Thread 'Thread-9': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:48.221 Thread 'Thread-9': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:24:48.227 Thread 'Thread-9': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/tmp/ipython-input-6-1590317818.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_sampled = df.groupby('label').apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Dataset total: 9999 échantillons\n",
            "Distribution des classes:\n",
            "label\n",
            "0.0    3333\n",
            "1.0    3333\n",
            "2.0    3333\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-25 14:26:51.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:26:51.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:26:51.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Splits créés:\n",
            "  - Train: 6999 échantillons (70.0%)\n",
            "  - Validation: 1000 échantillons (10.0%)\n",
            "  - Test: 2000 échantillons (20.0%)\n",
            "\n",
            "📊 Distribution par split:\n",
            "  Train: {0.0: 0.3333333333333333, 1.0: 0.3333333333333333, 2.0: 0.3333333333333333}\n",
            "  Val: {0.0: 0.334, 1.0: 0.333, 2.0: 0.333}\n",
            "  Test: {0.0: 0.333, 1.0: 0.3335, 2.0: 0.3335}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250725_142652-atz2mcpv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test/runs/atz2mcpv' target=\"_blank\">proud-armadillo-4</a></strong> to <a href='https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test' target=\"_blank\">https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test/runs/atz2mcpv' target=\"_blank\">https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test/runs/atz2mcpv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset avec splits uploadé vers W&B\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">proud-armadillo-4</strong> at: <a href='https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test/runs/atz2mcpv' target=\"_blank\">https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test/runs/atz2mcpv</a><br> View project at: <a href='https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test' target=\"_blank\">https://wandb.ai/k_benyahia-pstb/climate-sentiment-lora-train-val-test</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250725_142652-atz2mcpv/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 5. TOKENISATION POUR T5 (SEQ2SEQ)\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "p1-TUmglxKc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def prepare_seq2seq_data(examples):\n",
        "    \"\"\"Prépare les données pour T5 en format seq2seq.\"\"\"\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for text, label in zip(examples[\"text\"], examples[\"label\"]):\n",
        "        input_text = f\"classify sentiment: {text}\"\n",
        "        target_text = [\"negative\", \"neutral\", \"positive\"][int(label)]\n",
        "        inputs.append(input_text)\n",
        "        targets.append(target_text)\n",
        "\n",
        "    # Tokenisation\n",
        "    model_inputs = tokenizer(inputs, max_length=256, truncation=True, padding=True)\n",
        "    labels = tokenizer(targets, max_length=16, truncation=True, padding=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Création des datasets pour chaque split\n",
        "datasets = {}\n",
        "for split_name, split_df in data_splits.items():\n",
        "    dataset = Dataset.from_pandas(split_df)\n",
        "    tokenized = dataset.map(prepare_seq2seq_data, batched=True, remove_columns=dataset.column_names)\n",
        "    tokenized.set_format(type=\"torch\")\n",
        "    datasets[split_name] = tokenized\n",
        "\n",
        "print(\"✅ Tokenisation terminée pour tous les splits\")\n",
        "\n",
        "# Vérification de chaque split\n",
        "for split_name, dataset in datasets.items():\n",
        "    sanity_check_dataset(dataset, split_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dd186a625c194bf58af3ce2dcbe57707",
            "fe93f602b357497991ac1ee266936d53",
            "67d3f1a2901c4b09b804bb1e637ed742",
            "4704d3919433489c92fb6026cc022221",
            "9392ef75167241668d0c2624c3dc77af",
            "1a835167e3e64d048142459890bb2e21",
            "c6b92b7b1a694081b3e400ee316e2d9e",
            "0c266288792d4235a8f6f250be4062e0",
            "2db25bb132164e7099a902d8a6e1993f",
            "7f00b022e4794a268cdcff5f982f3b32",
            "19ff50a03f1a4b97ae6cd25b0196610b",
            "f8847145801a4dc1a21d7c09db768274",
            "1688fad51d394761915959d32db5721b",
            "6ecef832ae954f028a3af7da86e68e52",
            "e895c24ff16d4ba2a23e127163121861",
            "985539d20ccf41eeb3400b2cfd16b7cb",
            "a40293716c4946ab8b6457447712eef1",
            "3efbf6cacfca4246b78b8cfe1955976e",
            "edcef05a1511480a8c77de0a78a12161",
            "07f0fc6ab4f841e090c8d528eaec76ae",
            "ae56a6cd87fc4b8ca9e434f39c8f1638",
            "6f2f0622693a4b97b28b7b4c3799979b",
            "8dfcabab9bc44fc8bb575b0dc3a8fd0d",
            "83b1d611456d4146863779e86bd72e13",
            "726fb502d28c406c91dc938929d168cc",
            "35d9b35179614a14886125675b0a59f0",
            "4148b44add8444c29eeab43d367fb9c5",
            "53a4da0f26ff4df781fdf70814ab4748",
            "d5df04790cc64d398f9ccfabfc7355fb",
            "4eecbdef76ea42d59e9f6e3833eb5024",
            "87ee45f8b3de4ce3a91073e76e9ed5d8",
            "b522428659d64ea6ae965a45813293f3",
            "0a63e213a6474d7f9d30d29bad4da09d"
          ]
        },
        "id": "7-tF6K0AxKUZ",
        "outputId": "329ecf9a-3aa3-4f6b-a12a-ca7a34da2095"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6999 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd186a625c194bf58af3ce2dcbe57707"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8847145801a4dc1a21d7c09db768274"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dfcabab9bc44fc8bb575b0dc3a8fd0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenisation terminée pour tous les splits\n",
            "📊 Dataset train: 6999 échantillons\n",
            "Exemple 0: {'input_ids': tensor([  853,  4921,  6493,    10,  8586,   172,    22,     7,  1988,    24,\n",
            "            3,    88,    47,    16,  7764,  7807,   383,  2262,   152,   152,\n",
            "          904,  7120,  4973,     7,   365,  3044,    57,   245, 10702,    15,\n",
            "           26,  8468,  2279,   276,  3171,  9135,    10,    37,  2601,    47,\n",
            "          310,    46, 13876,  2412,   443,    11,    34,    47,    66,    80,\n",
            "          307,  3562,  1469,     5,     1,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([2841,    1])}\n",
            "Exemple 1: {'input_ids': tensor([  853,  4921,  6493,    10,    27,     7,   132, 10568, 21700,  3298,\n",
            "         1506,    58,     3,   476,  3205,     5,   290,    19,   233, 12798,\n",
            "           15,     9,    26,    11,  7707,  1602,     5,     1,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([2841,    1])}\n",
            "Exemple 2: {'input_ids': tensor([  853,  4921,  6493,    10, 10759,    63,   227,  1881,   226,   106,\n",
            "         5752,   845,   452,    12,  9100,    21,  3298,  3338,     7,  1820,\n",
            "        15772,  5362, 14507, 12473,     8,  7294,    30,     3,     9,  4740,\n",
            "            3,  4605,    51,    53,     8,  4024,   492,     8, 13731,    58,\n",
            "         2867,    33,  1966,     5,     1,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([2841,    1])}\n",
            "✅ Dataset train validé\n",
            "📊 Dataset validation: 1000 échantillons\n",
            "Exemple 0: {'input_ids': tensor([  853,  4921,  6493,    10,   205, 12569,    10,  1363,   115, 11535,\n",
            "           19,    59,     3,     9,  1282,   568,    37, 22784,    47,    92,\n",
            "            3,     7,    75, 16056,    38,     3,    89,  2406,    11,     3,\n",
            "            9,   194,    12,     3,  5082,    13,   502,     1,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0]), 'labels': tensor([7163,    1])}\n",
            "Exemple 1: {'input_ids': tensor([  853,  4921,  6493,    10,  1015,    13,     8,  3298,    10,   460,\n",
            "         2266,    56,    36,   166,   215,   756,  8613,   254,    13,  1252,\n",
            "        14811,  3892,   271,     7,    43,   118,  4945,    28,  3298,   483,\n",
            "           21,  3986,    13,  2909,    13,   203,     5,   100,    19,  1327,\n",
            "         1100,     5, 21295,    95,     5,     1,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0]), 'labels': tensor([7163,    1])}\n",
            "Exemple 2: {'input_ids': tensor([  853,  4921,  6493,    10,   101,    31,   162,    66,   530,   204,\n",
            "         4525,   203,   646,    30,    48,  3596, 24210,    11,    66,     8,\n",
            "         1146,    95,     7,   214,    13,     3,     9,    72,  4034, 13618,\n",
            "            5,    96,  5680,  1776,    96,   121,    60,  2244,  3095,  2121,\n",
            "          121,   121,    16,   957,  4305,  4609,     1,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0]), 'labels': tensor([7163,    1])}\n",
            "✅ Dataset validation validé\n",
            "📊 Dataset test: 2000 échantillons\n",
            "Exemple 0: {'input_ids': tensor([  853,  4921,  6493,    10,  9165,  6490,  3098,    16,  1252,  1202,\n",
            "        17282,  1080,   788,    12,   993,    16,  4146, 22122,    65,     3,\n",
            "            7, 22411,    37,  1309,    19,  3654,     5,     1,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([2841,    1])}\n",
            "Exemple 1: {'input_ids': tensor([  853,  4921,  6493,    10, 21430,  2042,   747,    52, 13445,    19,\n",
            "          223,    30,  4030,   298,  4627,    56,  1560,   524,     3,     9,\n",
            "         5844,     4,  2564,   234,    16,   460,  1828,  2163,     5, 15971,\n",
            "            3,  3380,  5402,    18,   413,   192,   996,  6116,    30,     8,\n",
            "        12908,    15,    26, 10282,   628,  6696,    16,   495,    79,   174,\n",
            "           12, 29766,     8,   628,  2478,   274,     8, 16233,   668,  2253,\n",
            "        22506,   865,    48,   847,     5,     1,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([1465,    1])}\n",
            "Exemple 2: {'input_ids': tensor([  853,  4921,  6493,    10, 23043,  9010,   537,  5438,   235,     7,\n",
            "          102,    88,  2234, 18171,    53,   605, 14619,   147, 26461,     9,\n",
            "         4877,     8,  1088,    24,  6672,  1429,   210,  2366,  1935,     8,\n",
            "            3,     9, 10496,     9,   120,   102,     7,    15,    12,  1837,\n",
            "           16,    70,  6556,     7,    19,  5107,   120,   885,    12,     3,\n",
            "        11866,  3574,   610,   233,     3,     2,     1,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([7163,    1])}\n",
            "✅ Dataset test validé\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 6. MODÈLE T5 AVEC LORA\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "HEWC3YIP29_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_lora_model():\n",
        "    \"\"\"Configure le modèle T5 avec LoRA pour fine-tuning efficace.\"\"\"\n",
        "\n",
        "    base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=16,\n",
        "        lora_alpha=32,\n",
        "        target_modules=[\"q\", \"v\"],\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(base_model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model\n",
        "\n",
        "model = setup_lora_model()\n",
        "sanity_check_model(model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unTMTufw2-h0",
        "outputId": "824f9d2a-32f1-4c02-d0fa-af9338c54df4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 589,824 || all params: 61,096,448 || trainable%: 0.9654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Forward pass OK - Loss: 0.3286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 7. MÉTRIQUES ET ENTRAÎNEMENT\n",
        "# ====================================================================\n"
      ],
      "metadata": {
        "id": "hkcPAbjHxQjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Métriques d'évaluation personnalisées.\"\"\"\n",
        "    predictions = eval_pred.predictions\n",
        "    labels = eval_pred.label_ids\n",
        "\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]\n",
        "\n",
        "    predicted_tokens = np.argmax(predictions, axis=-1)\n",
        "    predicted_texts = tokenizer.batch_decode(predicted_tokens, skip_special_tokens=True)\n",
        "    label_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    sentiment_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
        "\n",
        "    pred_labels = [sentiment_map.get(text.strip().lower(), 1) for text in predicted_texts]\n",
        "    true_labels = [sentiment_map.get(text.strip().lower(), 1) for text in label_texts]\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    f1 = f1_score(true_labels, pred_labels, average=\"weighted\")\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
        "\n",
        "# Configuration de l'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora_climate_t5_train_val_test\",\n",
        "    per_device_train_batch_size=8 if DEVICE == \"cuda\" else 4,\n",
        "    per_device_eval_batch_size=8 if DEVICE == \"cuda\" else 4,\n",
        "    num_train_epochs=5,  # Plus d'époques pour voir l'évolution\n",
        "    learning_rate=5e-4,\n",
        "    weight_decay=0.01,\n",
        "    fp16=DEVICE == \"cuda\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,  # Évaluation plus fréquente\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    logging_steps=25,  # Logs plus fréquents\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"wandb\",\n",
        "    run_name=\"lora-t5-train-val-test\",\n",
        "    dataloader_num_workers=0,\n",
        ")\n",
        "\n",
        "# Trainer avec callback personnalisé\n",
        "loss_callback = LossTrackingCallback(datasets[\"test\"], tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=datasets[\"train\"],\n",
        "    eval_dataset=datasets[\"validation\"],  # Utilise validation pour l'évaluation pendant training\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[loss_callback]\n",
        ")\n",
        "\n",
        "def train_model():\n",
        "    \"\"\"Lance l'entraînement avec suivi détaillé des losses.\"\"\"\n",
        "    print(\"🚀 Début de l'entraînement avec tracking train/val/test losses...\")\n",
        "\n",
        "    # Reset des logs\n",
        "    global training_logs\n",
        "    training_logs = {\"train_loss\": [], \"val_loss\": [], \"test_loss\": [], \"epochs\": [], \"steps\": []}\n",
        "\n",
        "    with wandb.init(project=WANDB_PROJECT, job_type=\"training\", name=\"lora-t5-train-val-test\"):\n",
        "        # Entraînement\n",
        "        trainer.train()\n",
        "\n",
        "        # Sauvegarde\n",
        "        trainer.save_model(\"./lora_climate_t5_train_val_test\")\n",
        "        tokenizer.save_pretrained(\"./lora_climate_t5_train_val_test\")\n",
        "\n",
        "        # Évaluation finale sur tous les splits\n",
        "        print(\"\\n📊 Évaluation finale sur tous les splits:\")\n",
        "\n",
        "        train_metrics = trainer.evaluate(datasets[\"train\"])\n",
        "        val_metrics = trainer.evaluate(datasets[\"validation\"])\n",
        "        test_metrics = trainer.evaluate(datasets[\"test\"])\n",
        "\n",
        "        final_metrics = {\n",
        "            \"train_final\": train_metrics,\n",
        "            \"val_final\": val_metrics,\n",
        "            \"test_final\": test_metrics,\n",
        "            \"training_logs\": training_logs\n",
        "        }\n",
        "\n",
        "        wandb.log(final_metrics)\n",
        "\n",
        "        print(f\"📊 Résultats finaux:\")\n",
        "        print(f\"  Train - Accuracy: {train_metrics.get('eval_accuracy', 0):.3f}, F1: {train_metrics.get('eval_f1', 0):.3f}\")\n",
        "        print(f\"  Val   - Accuracy: {val_metrics.get('eval_accuracy', 0):.3f}, F1: {val_metrics.get('eval_f1', 0):.3f}\")\n",
        "        print(f\"  Test  - Accuracy: {test_metrics.get('eval_accuracy', 0):.3f}, F1: {test_metrics.get('eval_f1', 0):.3f}\")\n",
        "\n",
        "        return final_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkgROk3MxQWE",
        "outputId": "4b148c94-4384-4d95-916f-b8fddd45713a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-2553260242.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ====================================================================\n",
        "# 8. FONCTIONS DE VISUALISATION DES LOSSES\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "HvG_MsXTxYzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_losses():\n",
        "    \"\"\"Crée des graphiques interactifs des losses train/val/test.\"\"\"\n",
        "\n",
        "    if not training_logs[\"train_loss\"]:\n",
        "        st.warning(\"⚠️ Pas de données d'entraînement disponibles. Lancez d'abord l'entraînement.\")\n",
        "        return\n",
        "\n",
        "    # Graphique principal: Evolution des losses\n",
        "    fig_losses = go.Figure()\n",
        "\n",
        "    # Synchroniser les données (toutes les listes doivent avoir la même longueur)\n",
        "    min_length = min(len(training_logs[\"train_loss\"]),\n",
        "                     len(training_logs[\"val_loss\"]),\n",
        "                     len(training_logs[\"test_loss\"]))\n",
        "\n",
        "    steps = training_logs[\"steps\"][:min_length]\n",
        "\n",
        "    # Train loss\n",
        "    fig_losses.add_trace(go.Scatter(\n",
        "        x=steps,\n",
        "        y=training_logs[\"train_loss\"][:min_length],\n",
        "        mode='lines+markers',\n",
        "        name='Train Loss',\n",
        "        line=dict(color='blue', width=2),\n",
        "        marker=dict(size=4)\n",
        "    ))\n",
        "\n",
        "    # Validation loss\n",
        "    fig_losses.add_trace(go.Scatter(\n",
        "        x=steps,\n",
        "        y=training_logs[\"val_loss\"][:min_length],\n",
        "        mode='lines+markers',\n",
        "        name='Validation Loss',\n",
        "        line=dict(color='orange', width=2),\n",
        "        marker=dict(size=4)\n",
        "    ))\n",
        "\n",
        "    # Test loss\n",
        "    fig_losses.add_trace(go.Scatter(\n",
        "        x=steps,\n",
        "        y=training_logs[\"test_loss\"][:min_length],\n",
        "        mode='lines+markers',\n",
        "        name='Test Loss',\n",
        "        line=dict(color='red', width=2),\n",
        "        marker=dict(size=4)\n",
        "    ))\n",
        "\n",
        "    fig_losses.update_layout(\n",
        "        title=\"📈 Évolution des Losses pendant l'Entraînement\",\n",
        "        xaxis_title=\"Steps\",\n",
        "        yaxis_title=\"Loss\",\n",
        "        hovermode='x unified',\n",
        "        legend=dict(x=0.7, y=0.95),\n",
        "        height=500\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig_losses, use_container_width=True)\n",
        "\n",
        "    # Graphique secondaire: Loss finale par split\n",
        "    if min_length > 0:\n",
        "        final_losses = {\n",
        "            \"Train\": training_logs[\"train_loss\"][-1] if training_logs[\"train_loss\"] else 0,\n",
        "            \"Validation\": training_logs[\"val_loss\"][-1] if training_logs[\"val_loss\"] else 0,\n",
        "            \"Test\": training_logs[\"test_loss\"][-1] if training_logs[\"test_loss\"] else 0\n",
        "        }\n",
        "\n",
        "        fig_final = go.Figure(data=go.Bar(\n",
        "            x=list(final_losses.keys()),\n",
        "            y=list(final_losses.values()),\n",
        "            marker_color=['blue', 'orange', 'red'],\n",
        "            text=[f\"{v:.4f}\" for v in final_losses.values()],\n",
        "            textposition='auto'\n",
        "        ))\n",
        "\n",
        "        fig_final.update_layout(\n",
        "            title=\"📊 Losses Finales par Split\",\n",
        "            yaxis_title=\"Loss\",\n",
        "            height=400\n",
        "        )\n",
        "\n",
        "        st.plotly_chart(fig_final, use_container_width=True)\n",
        "\n",
        "def plot_dataset_distribution():\n",
        "    \"\"\"Graphique de distribution des données par split.\"\"\"\n",
        "\n",
        "    # Données pour le graphique\n",
        "    splits_data = []\n",
        "    for split_name, split_df in data_splits.items():\n",
        "        for label in [0, 1, 2]:\n",
        "            count = len(split_df[split_df['label'] == label])\n",
        "            splits_data.append({\n",
        "                'Split': split_name.capitalize(),\n",
        "                'Sentiment': ['Negative', 'Neutral', 'Positive'][label],\n",
        "                'Count': count\n",
        "            })\n",
        "\n",
        "    df_viz = pd.DataFrame(splits_data)\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    colors = ['#FF4B4B', '#FFA500', '#00CC88']\n",
        "    sentiments = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "    for i, sentiment in enumerate(sentiments):\n",
        "        data = df_viz[df_viz['Sentiment'] == sentiment]\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=data['Split'],\n",
        "            y=data['Count'],\n",
        "            name=sentiment,\n",
        "            marker_color=colors[i]\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"📊 Distribution des Classes par Split\",\n",
        "        xaxis_title=\"Split\",\n",
        "        yaxis_title=\"Nombre d'échantillons\",\n",
        "        barmode='group',\n",
        "        height=400\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig, use_container_width=True)"
      ],
      "metadata": {
        "id": "xE3Un8l2xYrt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ====================================================================\n",
        "# 9. SYSTÈME DE RETRIEVAL (inchangé)\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "r8G-yGJ6xf8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@st.cache_resource\n",
        "def build_retrieval_system():\n",
        "    \"\"\"Construction de l'index FAISS pour la recherche sémantique.\"\"\"\n",
        "    print(\"🔍 Construction de l'index de retrieval...\")\n",
        "\n",
        "    corpus = reddit_df[\"text\"].tolist()\n",
        "\n",
        "    if len(corpus) == 0:\n",
        "        return None, None, []\n",
        "\n",
        "    encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    embeddings = encoder.encode(corpus, batch_size=32, show_progress_bar=True)\n",
        "\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dimension)\n",
        "    index.add(np.array(embeddings).astype(\"float32\"))\n",
        "\n",
        "    print(f\"✅ Index construit: {len(corpus)} documents, dimension {dimension}\")\n",
        "\n",
        "    return encoder, index, corpus\n",
        "\n",
        "encoder, faiss_index, corpus = build_retrieval_system()\n",
        "\n",
        "if encoder is not None:\n",
        "    sanity_check_retrieval(encoder, faiss_index, corpus)\n",
        "\n",
        "def retrieve_documents(query, k=3, threshold=0.3):\n",
        "    \"\"\"Récupère les k documents les plus pertinents pour une query.\"\"\"\n",
        "    if encoder is None or faiss_index is None:\n",
        "        return [], []\n",
        "\n",
        "    query_embedding = encoder.encode([query])\n",
        "    scores, indices = faiss_index.search(\n",
        "        np.array(query_embedding).astype(\"float32\"),\n",
        "        min(k, len(corpus))\n",
        "    )\n",
        "\n",
        "    filtered_results = []\n",
        "    for score, idx in zip(scores[0], indices[0]):\n",
        "        if score > threshold and idx < len(corpus):\n",
        "            filtered_results.append((corpus[idx], score))\n",
        "\n",
        "    documents = [doc for doc, _ in filtered_results]\n",
        "    doc_scores = [score for _, score in filtered_results]\n",
        "\n",
        "    return documents, doc_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315,
          "referenced_widgets": [
            "31fd40bc89394cc699462dba7d1df588",
            "f3d53f02b7974f879d7ef27f17809ef0",
            "4b2e9bcc7fc5478e84641d0827511278",
            "ca375fd66da24c1582d6fe079ab55c88",
            "66b21978572d4ec19b935ea83db0f9cc",
            "5c879de03f894a4dbd35625122915313",
            "dbea01ac9fa444d6bffbc6bf25af7a4f",
            "aa60558605694c6cbfdb058a5a44f1e9",
            "d6f5da1882724d86bf9642278ce7153c",
            "f29db02b509f41cf976b471e24a8d335",
            "ae48bb80e44849feb3fdd0ee1388bd05"
          ]
        },
        "id": "lg4RoEV8xfyS",
        "outputId": "b93b9ceb-0eec-4150-95c1-21f8656c1759"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-25 14:27:04.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:04.247 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:04.248 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:04.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Construction de l'index de retrieval...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-25 14:27:04.754 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:04.755 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:04.756 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31fd40bc89394cc699462dba7d1df588"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-25 14:27:15.088 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.089 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.090 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Index construit: 9999 documents, dimension 384\n",
            "✅ Retrieval OK - Trouvé 2 documents\n",
            "  1. Score: 0.717 - Cooling the Heat on Climate The propaganda that changed things is when the Left dropped “man-made” f...\n",
            "  2. Score: 0.703 - How is what we’re doing causing climate change ? I would LOVE to see a source for that....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ====================================================================\n",
        "# 10. GÉNÉRATION DE RÉPONSES (inchangé)\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "ojcudIJmxpLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_sentiment(text):\n",
        "    \"\"\"Classification de sentiment avec le modèle fine-tuné.\"\"\"\n",
        "    input_text = f\"classify sentiment: {text}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=256, truncation=True).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=20,\n",
        "            num_beams=3,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    sentiment_map = {\"negative\": [0.8, 0.1, 0.1], \"neutral\": [0.1, 0.8, 0.1], \"positive\": [0.1, 0.1, 0.8]}\n",
        "    probs = sentiment_map.get(prediction.lower(), [0.33, 0.34, 0.33])\n",
        "\n",
        "    return prediction, np.array(probs)\n",
        "\n",
        "def generate_contextual_response(user_input, context_docs):\n",
        "    \"\"\"Génère une réponse contextuelle en utilisant le modèle fine-tuné.\"\"\"\n",
        "    context_text = \"\\n\".join([f\"- {doc[:200]}...\" for doc in context_docs[:3]])\n",
        "    prompt = f\"generate response: User asks about: {user_input}\\nContext: {context_text}\\nResponse:\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=400, truncation=True).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=150,\n",
        "            num_beams=3,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            early_stopping=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    if \"Response:\" in response:\n",
        "        response = response.split(\"Response:\")[-1].strip()\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "avDuPOeqxoyd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 11. INTERFACE STREAMLIT ENRICHIE\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "kXASyIIwxwpp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2QKvZUkAu4My"
      },
      "outputs": [],
      "source": [
        "def main_streamlit_app():\n",
        "    \"\"\"Interface utilisateur Streamlit complète avec graphiques de losses.\"\"\"\n",
        "\n",
        "    st.set_page_config(\n",
        "        page_title=\"🌍 Climate Sentiment AI - Train/Val/Test\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "\n",
        "    st.title(\"🌍 Climate Sentiment AI avec Splits Train/Val/Test\")\n",
        "    st.markdown(\"*Modèle T5 avec LoRA - Tracking détaillé des losses*\")\n",
        "\n",
        "    # Sidebar avec informations et contrôles\n",
        "    with st.sidebar:\n",
        "        st.header(\"📊 Informations Système\")\n",
        "        st.metric(\"Modèle\", MODEL_NAME)\n",
        "        st.metric(\"Device\", DEVICE)\n",
        "\n",
        "        # Métriques des splits\n",
        "        st.subheader(\"📂 Splits de Données\")\n",
        "        st.metric(\"Train\", f\"{len(data_splits['train'])} (70%)\")\n",
        "        st.metric(\"Validation\", f\"{len(data_splits['validation'])} (10%)\")\n",
        "        st.metric(\"Test\", f\"{len(data_splits['test'])} (20%)\")\n",
        "\n",
        "        st.divider()\n",
        "\n",
        "        # Contrôles d'entraînement\n",
        "        st.subheader(\"🚀 Entraînement\")\n",
        "        if st.button(\"🏃 Lancer Entraînement\", type=\"primary\"):\n",
        "            with st.spinner(\"Entraînement en cours... (plusieurs minutes)\"):\n",
        "                training_results = train_model()\n",
        "            st.success(\"✅ Entraînement terminé!\")\n",
        "            st.rerun()  # Rafraîchir pour afficher les graphiques\n",
        "\n",
        "        if st.button(\"📊 Évaluer sur Test Set\"):\n",
        "            with st.spinner(\"Évaluation en cours...\"):\n",
        "                test_metrics = trainer.evaluate(datasets[\"test\"])\n",
        "            st.success(\"✅ Évaluation terminée!\")\n",
        "            st.json(test_metrics)\n",
        "\n",
        "    # Onglets principaux\n",
        "    tab1, tab2, tab3, tab4 = st.tabs([\"🚀 Application\", \"📈 Losses & Métriques\", \"📊 Analyse Données\", \"📚 Documentation\"])\n",
        "\n",
        "    with tab1:\n",
        "        # Interface de test du modèle\n",
        "        col1, col2 = st.columns([2, 1])\n",
        "\n",
        "        with col1:\n",
        "            st.header(\"💬 Test du Système\")\n",
        "\n",
        "            user_input = st.text_area(\n",
        "                \"Entrez votre message sur le climat:\",\n",
        "                value=\"Renewable energy technologies are becoming more affordable and efficient.\",\n",
        "                height=100\n",
        "            )\n",
        "\n",
        "            if st.button(\"🚀 Analyser & Répondre\", type=\"primary\"):\n",
        "                if user_input.strip():\n",
        "\n",
        "                    # Phase 1: Classification sentiment\n",
        "                    with st.spinner(\"🔍 Classification du sentiment...\"):\n",
        "                        sentiment_pred, sentiment_probs = classify_sentiment(user_input)\n",
        "\n",
        "                    # Affichage sentiment\n",
        "                    st.subheader(\"📊 Analyse de Sentiment\")\n",
        "                    fig = go.Figure(data=go.Bar(\n",
        "                        x=[\"Négatif\", \"Neutre\", \"Positif\"],\n",
        "                        y=sentiment_probs,\n",
        "                        marker_color=[\"#FF4B4B\", \"#FFA500\", \"#00CC88\"]\n",
        "                    ))\n",
        "                    fig.update_layout(\n",
        "                        title=f\"Prédiction: {sentiment_pred.capitalize()}\",\n",
        "                        height=300,\n",
        "                        showlegend=False\n",
        "                    )\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                    # Phase 2: Retrieval\n",
        "                    with st.spinner(\"🔍 Recherche de contexte pertinent...\"):\n",
        "                        context_docs, context_scores = retrieve_documents(user_input, k=5)\n",
        "\n",
        "                    if context_docs:\n",
        "                        st.subheader(\"📚 Contexte Récupéré\")\n",
        "                        for i, (doc, score) in enumerate(zip(context_docs[:3], context_scores[:3])):\n",
        "                            with st.expander(f\"Document {i+1} (Score: {score:.3f})\"):\n",
        "                                st.write(doc[:300] + \"...\" if len(doc) > 300 else doc)\n",
        "\n",
        "                    # Phase 3: Génération\n",
        "                    with st.spinner(\"✍️ Génération de la réponse...\"):\n",
        "                        response = generate_contextual_response(user_input, context_docs)\n",
        "\n",
        "                    st.subheader(\"🤖 Réponse Générée\")\n",
        "                    st.write(response)\n",
        "\n",
        "                    # Métriques qualité\n",
        "                    if context_docs:\n",
        "                        scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
        "                        rouge_score = scorer.score(user_input, response)[\"rougeL\"].fmeasure\n",
        "                        st.metric(\"Score ROUGE-L\", f\"{rouge_score:.3f}\")\n",
        "\n",
        "                    # Log interaction vers W&B\n",
        "                    with wandb.init(project=WANDB_PROJECT, job_type=\"inference\"):\n",
        "                        wandb.log({\n",
        "                            \"user_input\": user_input,\n",
        "                            \"sentiment_prediction\": sentiment_pred,\n",
        "                            \"sentiment_probs\": sentiment_probs.tolist(),\n",
        "                            \"context_docs\": context_docs,\n",
        "                            \"response\": response,\n",
        "                            \"num_context_docs\": len(context_docs)\n",
        "                        })\n",
        "                else:\n",
        "                    st.warning(\"⚠️ Veuillez saisir un message.\")\n",
        "\n",
        "        with col2:\n",
        "            st.header(\"📈 Métriques & Feedback\")\n",
        "\n",
        "            # Métriques modèle\n",
        "            st.subheader(\"🎯 Performance Modèle\")\n",
        "            if training_logs[\"train_loss\"]:\n",
        "                st.metric(\"Train Loss (dernière)\", f\"{training_logs['train_loss'][-1]:.4f}\")\n",
        "                if training_logs[\"val_loss\"]:\n",
        "                    st.metric(\"Val Loss (dernière)\", f\"{training_logs['val_loss'][-1]:.4f}\")\n",
        "                if training_logs[\"test_loss\"]:\n",
        "                    st.metric(\"Test Loss (dernière)\", f\"{training_logs['test_loss'][-1]:.4f}\")\n",
        "            else:\n",
        "                st.info(\"Lancez l'entraînement pour voir les métriques\")\n",
        "\n",
        "            # Système de feedback\n",
        "            st.subheader(\"💬 Feedback\")\n",
        "\n",
        "            if 'response' in locals():\n",
        "                feedback_rating = st.radio(\n",
        "                    \"Évaluez la réponse:\",\n",
        "                    options=[\"👍 Excellente\", \"👌 Bonne\", \"👎 Mauvaise\"],\n",
        "                    horizontal=True\n",
        "                )\n",
        "\n",
        "                feedback_comment = st.text_area(\"Commentaire (optionnel):\", height=80)\n",
        "\n",
        "                if st.button(\"📤 Envoyer Feedback\"):\n",
        "                    feedback_data = {\n",
        "                        \"timestamp\": time.time(),\n",
        "                        \"user_input\": user_input,\n",
        "                        \"response\": response,\n",
        "                        \"rating\": feedback_rating,\n",
        "                        \"comment\": feedback_comment,\n",
        "                        \"sentiment_pred\": sentiment_pred\n",
        "                    }\n",
        "\n",
        "                    # Sauvegarde locale\n",
        "                    with open(\"feedback_log.jsonl\", \"a\") as f:\n",
        "                        json.dump(feedback_data, f)\n",
        "                        f.write(\"\\n\")\n",
        "\n",
        "                    # Log vers W&B\n",
        "                    with wandb.init(project=WANDB_PROJECT, job_type=\"feedback\"):\n",
        "                        wandb.log(feedback_data)\n",
        "\n",
        "                    st.success(\"✅ Merci pour votre feedback!\")\n",
        "\n",
        "    with tab2:\n",
        "        st.header(\"📈 Tracking des Losses et Métriques\")\n",
        "\n",
        "        # Graphiques des losses\n",
        "        st.subheader(\"📊 Évolution des Losses pendant l'Entraînement\")\n",
        "        plot_training_losses()\n",
        "\n",
        "        # Tableau récapitulatif des métriques\n",
        "        if training_logs[\"train_loss\"]:\n",
        "            st.subheader(\"📋 Résumé des Métriques\")\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "\n",
        "            with col1:\n",
        "                st.metric(\n",
        "                    \"🔵 Train Loss\",\n",
        "                    f\"{training_logs['train_loss'][-1]:.4f}\" if training_logs[\"train_loss\"] else \"N/A\",\n",
        "                    delta=f\"{training_logs['train_loss'][-1] - training_logs['train_loss'][0]:.4f}\" if len(training_logs[\"train_loss\"]) > 1 else None\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                st.metric(\n",
        "                    \"🟠 Validation Loss\",\n",
        "                    f\"{training_logs['val_loss'][-1]:.4f}\" if training_logs[\"val_loss\"] else \"N/A\",\n",
        "                    delta=f\"{training_logs['val_loss'][-1] - training_logs['val_loss'][0]:.4f}\" if len(training_logs[\"val_loss\"]) > 1 else None\n",
        "                )\n",
        "\n",
        "            with col3:\n",
        "                st.metric(\n",
        "                    \"🔴 Test Loss\",\n",
        "                    f\"{training_logs['test_loss'][-1]:.4f}\" if training_logs[\"test_loss\"] else \"N/A\",\n",
        "                    delta=f\"{training_logs['test_loss'][-1] - training_logs['test_loss'][0]:.4f}\" if len(training_logs[\"test_loss\"]) > 1 else None\n",
        "                )\n",
        "\n",
        "            # Statistiques détaillées\n",
        "            if len(training_logs[\"train_loss\"]) > 0:\n",
        "                st.subheader(\"📊 Statistiques d'Entraînement\")\n",
        "\n",
        "                stats_data = {\n",
        "                    \"Métrique\": [\"Train Loss\", \"Validation Loss\", \"Test Loss\"],\n",
        "                    \"Valeur Initiale\": [\n",
        "                        f\"{training_logs['train_loss'][0]:.4f}\" if training_logs[\"train_loss\"] else \"N/A\",\n",
        "                        f\"{training_logs['val_loss'][0]:.4f}\" if training_logs[\"val_loss\"] else \"N/A\",\n",
        "                        f\"{training_logs['test_loss'][0]:.4f}\" if training_logs[\"test_loss\"] else \"N/A\"\n",
        "                    ],\n",
        "                    \"Valeur Finale\": [\n",
        "                        f\"{training_logs['train_loss'][-1]:.4f}\" if training_logs[\"train_loss\"] else \"N/A\",\n",
        "                        f\"{training_logs['val_loss'][-1]:.4f}\" if training_logs[\"val_loss\"] else \"N/A\",\n",
        "                        f\"{training_logs['test_loss'][-1]:.4f}\" if training_logs[\"test_loss\"] else \"N/A\"\n",
        "                    ],\n",
        "                    \"Amélioration\": [\n",
        "                        f\"{((training_logs['train_loss'][0] - training_logs['train_loss'][-1]) / training_logs['train_loss'][0] * 100):.1f}%\" if len(training_logs[\"train_loss\"]) > 1 else \"N/A\",\n",
        "                        f\"{((training_logs['val_loss'][0] - training_logs['val_loss'][-1]) / training_logs['val_loss'][0] * 100):.1f}%\" if len(training_logs[\"val_loss\"]) > 1 else \"N/A\",\n",
        "                        f\"{((training_logs['test_loss'][0] - training_logs['test_loss'][-1]) / training_logs['test_loss'][0] * 100):.1f}%\" if len(training_logs[\"test_loss\"]) > 1 else \"N/A\"\n",
        "                    ]\n",
        "                }\n",
        "\n",
        "                st.dataframe(pd.DataFrame(stats_data), use_container_width=True)\n",
        "        else:\n",
        "            st.info(\"🚀 Lancez l'entraînement pour voir les graphiques de losses\")\n",
        "            st.markdown(\"\"\"\n",
        "            **Ce que vous verrez après l'entraînement :**\n",
        "            - 📈 Graphique interactif des losses train/validation/test\n",
        "            - 📊 Barres comparatives des losses finales\n",
        "            - 📋 Tableau récapitulatif avec amélioration en %\n",
        "            - 📉 Métriques d'overfitting/underfitting\n",
        "            \"\"\")\n",
        "\n",
        "    with tab3:\n",
        "        st.header(\"📊 Analyse des Données\")\n",
        "\n",
        "        # Distribution des splits\n",
        "        st.subheader(\"📂 Distribution des Splits\")\n",
        "        plot_dataset_distribution()\n",
        "\n",
        "        # Statistiques par split\n",
        "        st.subheader(\"📈 Statistiques Détaillées\")\n",
        "\n",
        "        splits_stats = []\n",
        "        for split_name, split_df in data_splits.items():\n",
        "            stats = {\n",
        "                \"Split\": split_name.capitalize(),\n",
        "                \"Total\": len(split_df),\n",
        "                \"Negative\": len(split_df[split_df['label'] == 0]),\n",
        "                \"Neutral\": len(split_df[split_df['label'] == 1]),\n",
        "                \"Positive\": len(split_df[split_df['label'] == 2]),\n",
        "                \"Longueur Moyenne\": split_df['text'].str.len().mean().round(1),\n",
        "                \"Longueur Médiane\": split_df['text'].str.len().median()\n",
        "            }\n",
        "            splits_stats.append(stats)\n",
        "\n",
        "        st.dataframe(pd.DataFrame(splits_stats), use_container_width=True)\n",
        "\n",
        "        # Analyse de la longueur des textes\n",
        "        st.subheader(\"📏 Distribution de la Longueur des Textes\")\n",
        "\n",
        "        fig_lengths = go.Figure()\n",
        "\n",
        "        for split_name, split_df in data_splits.items():\n",
        "            lengths = split_df['text'].str.len()\n",
        "            fig_lengths.add_trace(go.Histogram(\n",
        "                x=lengths,\n",
        "                name=split_name.capitalize(),\n",
        "                opacity=0.7,\n",
        "                nbinsx=30\n",
        "            ))\n",
        "\n",
        "        fig_lengths.update_layout(\n",
        "            title=\"Distribution de la Longueur des Textes par Split\",\n",
        "            xaxis_title=\"Longueur (caractères)\",\n",
        "            yaxis_title=\"Fréquence\",\n",
        "            barmode='overlay',\n",
        "            height=400\n",
        "        )\n",
        "\n",
        "        st.plotly_chart(fig_lengths, use_container_width=True)\n",
        "\n",
        "        # Exemples par classe\n",
        "        st.subheader(\"📝 Exemples par Classe Sentiment\")\n",
        "\n",
        "        sentiment_names = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "        cols = st.columns(3)\n",
        "\n",
        "        for i, (col, sentiment) in enumerate(zip(cols, sentiment_names)):\n",
        "            with col:\n",
        "                st.markdown(f\"**{sentiment}**\")\n",
        "                examples = data_splits[\"train\"][data_splits[\"train\"][\"label\"] == i][\"text\"].head(3)\n",
        "                for j, example in enumerate(examples):\n",
        "                    with st.expander(f\"Exemple {j+1}\"):\n",
        "                        st.write(example[:200] + \"...\" if len(example) > 200 else example)\n",
        "\n",
        "    with tab4:\n",
        "        st.header(\"📚 Documentation Technique\")\n",
        "\n",
        "        st.subheader(\"🎯 Architecture du Système\")\n",
        "        st.markdown(\"\"\"\n",
        "        **Modèle Unifié T5 avec LoRA:**\n",
        "        - **Base**: T5-small (60M paramètres)\n",
        "        - **LoRA**: Adaptation efficace avec ~1M paramètres entraînables\n",
        "        - **Tâches**: Classification de sentiment + Génération contextuelle\n",
        "\n",
        "        **Splits de Données:**\n",
        "        - **Train (70%)**: Entraînement principal du modèle\n",
        "        - **Validation (10%)**: Sélection d'hyperparamètres et early stopping\n",
        "        - **Test (20%)**: Évaluation finale non biaisée\n",
        "\n",
        "        **Métriques Trackées:**\n",
        "        - **Train Loss**: Capacité d'apprentissage sur les données d'entraînement\n",
        "        - **Validation Loss**: Généralisation pendant l'entraînement\n",
        "        - **Test Loss**: Performance finale sur données non vues\n",
        "        \"\"\")\n",
        "\n",
        "        st.subheader(\"📈 Interprétation des Graphiques\")\n",
        "        st.markdown(\"\"\"\n",
        "        **Signaux Positifs:**\n",
        "        - 📉 Train et Val loss diminuent ensemble\n",
        "        - 🎯 Écart raisonnable entre Train et Val loss\n",
        "        - ✅ Test loss proche de la Val loss\n",
        "\n",
        "        **Signaux d'Alerte:**\n",
        "        - 📈 Val loss augmente alors que Train loss diminue (overfitting)\n",
        "        - 📊 Écart très important Train vs Val loss (overfitting)\n",
        "        - ⚠️ Test loss beaucoup plus élevée que Val loss (data leakage)\n",
        "\n",
        "        **Actions Correctives:**\n",
        "        - **Overfitting**: Réduire learning rate, augmenter regularization\n",
        "        - **Underfitting**: Augmenter complexité modèle, plus d'époques\n",
        "        - **Data leakage**: Vérifier stratification des splits\n",
        "        \"\"\")\n",
        "\n",
        "        st.subheader(\"🔧 Configuration LoRA\")\n",
        "        st.code(\"\"\"\n",
        "        LoraConfig(\n",
        "            task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "            r=16,                    # Rang des matrices (compromis capacité/efficacité)\n",
        "            lora_alpha=32,           # Facteur de scaling (généralement 2*r)\n",
        "            target_modules=[\"q\", \"v\"], # Modules d'attention adaptés\n",
        "            lora_dropout=0.05,       # Régularisation\n",
        "            bias=\"none\"              # Pas d'adaptation des biais\n",
        "        )\n",
        "        \"\"\", language=\"python\")\n",
        "\n",
        "        st.subheader(\"⚡ Optimisations Performance\")\n",
        "        st.markdown(\"\"\"\n",
        "        **Mémoire:**\n",
        "        - FP16 automatique sur GPU\n",
        "        - Batch sizes adaptatives selon hardware\n",
        "        - Gradient accumulation si nécessaire\n",
        "\n",
        "        **Calcul:**\n",
        "        - Multi-threading contrôlé sur CPU\n",
        "        - Evaluation stratégique (tous les 50 steps)\n",
        "        - Caching Streamlit pour éviter recomputation\n",
        "\n",
        "        **I/O:**\n",
        "        - Tokenisation en batch\n",
        "        - Sauvegarde périodique des checkpoints\n",
        "        - Logs structurés vers W&B\n",
        "        \"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 12. ÉVALUATION END-TO-END AMÉLIORÉE\n",
        "# ====================================================================\n"
      ],
      "metadata": {
        "id": "zJO4BCB-0Aip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_system_performance_detailed(n_samples=50):\n",
        "    \"\"\"\n",
        "    Évaluation complète du système avec métriques détaillées par split.\n",
        "    \"\"\"\n",
        "    print(f\"📊 Évaluation détaillée sur {n_samples} échantillons par split...\")\n",
        "\n",
        "    results_by_split = {}\n",
        "\n",
        "    # Évaluer chaque split séparément\n",
        "    for split_name, split_df in data_splits.items():\n",
        "        if len(split_df) == 0:\n",
        "            continue\n",
        "\n",
        "        # Échantillonner\n",
        "        test_samples = split_df.sample(n=min(n_samples, len(split_df)), random_state=42)\n",
        "\n",
        "        split_results = {\n",
        "            \"sentiment_predictions\": [],\n",
        "            \"true_sentiments\": [],\n",
        "            \"retrieval_scores\": [],\n",
        "            \"rouge_scores\": [],\n",
        "            \"latencies\": []\n",
        "        }\n",
        "\n",
        "        print(f\"🔍 Évaluation sur {split_name} ({len(test_samples)} échantillons)...\")\n",
        "\n",
        "        for idx, row in tqdm.tqdm(test_samples.iterrows(), total=len(test_samples)):\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Classification sentiment\n",
        "            pred_sentiment, _ = classify_sentiment(row[\"text\"])\n",
        "            true_sentiment = [\"negative\", \"neutral\", \"positive\"][row[\"label\"]]\n",
        "\n",
        "            # Retrieval\n",
        "            docs, scores = retrieve_documents(row[\"text\"], k=3)\n",
        "            avg_retrieval_score = np.mean(scores) if scores else 0\n",
        "\n",
        "            # Génération\n",
        "            response = generate_contextual_response(row[\"text\"], docs) if docs else \"No context available.\"\n",
        "\n",
        "            # ROUGE\n",
        "            scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
        "            rouge_score = scorer.score(row[\"text\"], response)[\"rougeL\"].fmeasure\n",
        "\n",
        "            latency = time.time() - start_time\n",
        "\n",
        "            # Stockage\n",
        "            split_results[\"sentiment_predictions\"].append(pred_sentiment)\n",
        "            split_results[\"true_sentiments\"].append(true_sentiment)\n",
        "            split_results[\"retrieval_scores\"].append(avg_retrieval_score)\n",
        "            split_results[\"rouge_scores\"].append(rouge_score)\n",
        "            split_results[\"latencies\"].append(latency)\n",
        "\n",
        "        # Calcul métriques du split\n",
        "        sentiment_accuracy = accuracy_score(split_results[\"true_sentiments\"], split_results[\"sentiment_predictions\"])\n",
        "\n",
        "        split_metrics = {\n",
        "            \"sentiment_accuracy\": sentiment_accuracy,\n",
        "            \"avg_retrieval_relevance\": np.mean(split_results[\"retrieval_scores\"]),\n",
        "            \"avg_rouge_l\": np.mean(split_results[\"rouge_scores\"]),\n",
        "            \"avg_latency_seconds\": np.mean(split_results[\"latencies\"]),\n",
        "            \"total_samples\": len(test_samples),\n",
        "            \"detailed_results\": split_results\n",
        "        }\n",
        "\n",
        "        results_by_split[split_name] = split_metrics\n",
        "\n",
        "        print(f\"✅ {split_name} - Accuracy: {sentiment_accuracy:.3f}\")\n",
        "\n",
        "    # Log complet vers W&B\n",
        "    with wandb.init(project=WANDB_PROJECT, job_type=\"detailed-evaluation\"):\n",
        "        for split_name, metrics in results_by_split.items():\n",
        "            # Métriques générales\n",
        "            wandb.log({f\"{split_name}_{k}\": v for k, v in metrics.items() if k != \"detailed_results\"})\n",
        "\n",
        "            # Table détaillée\n",
        "            detailed = metrics[\"detailed_results\"]\n",
        "            eval_table = wandb.Table(\n",
        "                columns=[\"split\", \"true_sentiment\", \"pred_sentiment\", \"retrieval_score\", \"rouge_score\", \"latency\"],\n",
        "                data=list(zip(\n",
        "                    [split_name] * len(detailed[\"true_sentiments\"]),\n",
        "                    detailed[\"true_sentiments\"],\n",
        "                    detailed[\"sentiment_predictions\"],\n",
        "                    detailed[\"retrieval_scores\"],\n",
        "                    detailed[\"rouge_scores\"],\n",
        "                    detailed[\"latencies\"]\n",
        "                ))\n",
        "            )\n",
        "            wandb.log({f\"{split_name}_detailed_results\": eval_table})\n",
        "\n",
        "    return results_by_split"
      ],
      "metadata": {
        "id": "XAyt19jt0AZK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 13. POINT D'ENTRÉE PRINCIPAL\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "g-v3IU390H4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Point d'entrée principal avec gestion des splits train/val/test.\"\"\"\n",
        "\n",
        "    # Vérifications initiales\n",
        "    if len(reddit_df) == 0:\n",
        "        st.error(\"❌ Données non disponibles. Vérifiez le fichier CSV.\")\n",
        "        return\n",
        "\n",
        "    # Interface principale\n",
        "    main_streamlit_app()\n"
      ],
      "metadata": {
        "id": "68GwFnrZ0HPS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 14. FONCTIONS UTILITAIRES POUR ANALYSE AVANCÉE\n",
        "# ====================================================================\n"
      ],
      "metadata": {
        "id": "6ilm5-I80Ri-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_overfitting():\n",
        "    \"\"\"Analyse des signes d'overfitting/underfitting.\"\"\"\n",
        "    st.header(\"🔍 Analyse Overfitting/Underfitting\")\n",
        "\n",
        "    if not training_logs[\"train_loss\"] or not training_logs[\"val_loss\"]:\n",
        "        st.warning(\"⚠️ Données d'entraînement insuffisantes pour l'analyse\")\n",
        "        return\n",
        "\n",
        "    # Calculer métriques d'overfitting\n",
        "    final_train_loss = training_logs[\"train_loss\"][-1]\n",
        "    final_val_loss = training_logs[\"val_loss\"][-1]\n",
        "\n",
        "    overfitting_ratio = final_val_loss / final_train_loss if final_train_loss > 0 else 1\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        st.metric(\"🔵 Train Loss Finale\", f\"{final_train_loss:.4f}\")\n",
        "\n",
        "    with col2:\n",
        "        st.metric(\"🟠 Val Loss Finale\", f\"{final_val_loss:.4f}\")\n",
        "\n",
        "    with col3:\n",
        "        color = \"normal\"\n",
        "        if overfitting_ratio > 1.5:\n",
        "            color = \"inverse\"  # Rouge pour overfitting\n",
        "        elif overfitting_ratio < 0.8:\n",
        "            color = \"inverse\"  # Rouge pour comportement anormal\n",
        "\n",
        "        st.metric(\n",
        "            \"📊 Ratio Val/Train\",\n",
        "            f\"{overfitting_ratio:.2f}\",\n",
        "            delta=f\"{'⚠️ Overfitting' if overfitting_ratio > 1.5 else '✅ OK' if 0.8 <= overfitting_ratio <= 1.5 else '⚠️ Underfitting'}\"\n",
        "        )\n",
        "\n",
        "    # Diagnostic automatique\n",
        "    st.subheader(\"🔍 Diagnostic Automatique\")\n",
        "\n",
        "    if overfitting_ratio > 1.5:\n",
        "        st.error(\"\"\"\n",
        "        🚨 **Signes d'Overfitting Détectés**\n",
        "\n",
        "        **Recommandations:**\n",
        "        - Réduire le learning rate\n",
        "        - Augmenter la régularisation (dropout)\n",
        "        - Réduire le nombre d'époques\n",
        "        - Augmenter la taille du dataset de validation\n",
        "        \"\"\")\n",
        "    elif overfitting_ratio < 0.8:\n",
        "        st.warning(\"\"\"\n",
        "        ⚠️ **Comportement Anormal Détecté**\n",
        "\n",
        "        **Possibles causes:**\n",
        "        - Data leakage entre train et validation\n",
        "        - Validation set trop facile\n",
        "        - Problème dans le calcul des métriques\n",
        "        \"\"\")\n",
        "    else:\n",
        "        st.success(\"\"\"\n",
        "        ✅ **Entraînement Sain**\n",
        "\n",
        "        Le modèle montre une bonne généralisation avec un écart raisonnable\n",
        "        entre les performances train et validation.\n",
        "        \"\"\")\n",
        "\n",
        "def export_training_report():\n",
        "    \"\"\"Génère un rapport complet d'entraînement.\"\"\"\n",
        "    st.header(\"📄 Rapport d'Entraînement\")\n",
        "\n",
        "    if st.button(\"📋 Générer Rapport Complet\"):\n",
        "\n",
        "        # Collecter toutes les informations\n",
        "        report_data = {\n",
        "            \"configuration\": {\n",
        "                \"model_name\": MODEL_NAME,\n",
        "                \"device\": DEVICE,\n",
        "                \"dataset_size\": len(reddit_df),\n",
        "                \"train_size\": len(data_splits[\"train\"]),\n",
        "                \"val_size\": len(data_splits[\"validation\"]),\n",
        "                \"test_size\": len(data_splits[\"test\"])\n",
        "            },\n",
        "            \"training_results\": training_logs,\n",
        "            \"splits_distribution\": {\n",
        "                split_name: split_df['label'].value_counts().to_dict()\n",
        "                for split_name, split_df in data_splits.items()\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Sauvegarder en JSON\n",
        "        report_filename = f\"training_report_{int(time.time())}.json\"\n",
        "        with open(report_filename, \"w\") as f:\n",
        "            json.dump(report_data, f, indent=2)\n",
        "\n",
        "        st.success(f\"✅ Rapport sauvegardé: {report_filename}\")\n",
        "\n",
        "        # Afficher résumé\n",
        "        st.subheader(\"📊 Résumé du Rapport\")\n",
        "        st.json({\n",
        "            \"Total Samples\": len(reddit_df),\n",
        "            \"Training Steps\": len(training_logs[\"steps\"]) if training_logs[\"steps\"] else 0,\n",
        "            \"Best Train Loss\": min(training_logs[\"train_loss\"]) if training_logs[\"train_loss\"] else \"N/A\",\n",
        "            \"Best Val Loss\": min(training_logs[\"val_loss\"]) if training_logs[\"val_loss\"] else \"N/A\",\n",
        "            \"Model Saved\": os.path.exists(\"./lora_climate_t5_train_val_test\")\n",
        "        })"
      ],
      "metadata": {
        "id": "HK0179is0RUo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================================\n",
        "# 15. LANCEMENT DE L'APPLICATION\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "b-UHWqwI0ei7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Vérification des dépendances\n",
        "    try:\n",
        "        import streamlit as st\n",
        "        import wandb\n",
        "        import torch\n",
        "        import transformers\n",
        "        import peft\n",
        "        import faiss\n",
        "        import sentence_transformers\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        print(\"✅ Toutes les dépendances sont installées\")\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"❌ Dépendance manquante: {e}\")\n",
        "        print(\"Installez avec: pip install streamlit wandb torch transformers peft faiss-cpu sentence-transformers rouge-score plotly pandas numpy tqdm scikit-learn\")\n",
        "        exit(1)\n",
        "\n",
        "    # Configuration logging\n",
        "    import logging\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    # Message de bienvenue\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"🌍 CLIMATE SENTIMENT AI - VERSION TRAIN/VAL/TEST\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"📱 Interface: Streamlit avec graphiques de losses\")\n",
        "    print(f\"🤖 Modèle: {MODEL_NAME} avec LoRA\")\n",
        "    print(f\"💾 Device: {DEVICE}\")\n",
        "    print(f\"📊 Splits: Train({len(data_splits['train'])}), Val({len(data_splits['validation'])}), Test({len(data_splits['test'])})\")\n",
        "    print(f\"🔍 Corpus: {len(corpus) if corpus else 0} documents indexés\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Lancement de l'interface\n",
        "    main()\n",
        "\n",
        "    # Options avancées dans la sidebar\n",
        "    with st.sidebar:\n",
        "        st.divider()\n",
        "        st.header(\"🔧 Analyses Avancées\")\n",
        "\n",
        "        if st.button(\"🔍 Analyser Overfitting\"):\n",
        "            analyze_overfitting()\n",
        "\n",
        "        if st.button(\"📄 Exporter Rapport\"):\n",
        "            export_training_report()\n",
        "\n",
        "        if st.button(\"📊 Évaluation Détaillée\"):\n",
        "            with st.spinner(\"Évaluation détaillée en cours...\"):\n",
        "                detailed_results = evaluate_system_performance_detailed(30)\n",
        "            st.success(\"✅ Évaluation terminée!\")\n",
        "            st.json({split: {k: v for k, v in metrics.items() if k != \"detailed_results\"}\n",
        "                    for split, metrics in detailed_results.items()})\n",
        "\n",
        "        # Informations debug\n",
        "        with st.expander(\"🐛 Debug Info\"):\n",
        "            st.write(\"**Statut Modèle:**\")\n",
        "            if 'model' in globals():\n",
        "                trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "                total_params = sum(p.numel() for p in model.parameters())\n",
        "                st.write(f\"- Paramètres entraînables: {trainable_params:,}\")\n",
        "                st.write(f\"- Paramètres totaux: {total_params:,}\")\n",
        "                st.write(f\"- Ratio LoRA: {trainable_params/total_params*100:.2f}%\")\n",
        "\n",
        "            st.write(\"**Statut Données:**\")\n",
        "            for split_name, split_data in datasets.items():\n",
        "                st.write(f\"- {split_name}: {len(split_data)} échantillons\")\n",
        "\n",
        "            st.write(\"**Logs Entraînement:**\")\n",
        "            st.write(f\"- Steps trackés: {len(training_logs['steps'])}\")\n",
        "            st.write(f\"- Train losses: {len(training_logs['train_loss'])}\")\n",
        "            st.write(f\"- Val losses: {len(training_logs['val_loss'])}\")\n",
        "            st.write(f\"- Test losses: {len(training_logs['test_loss'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtABGb2N0cxE",
        "outputId": "ae6f58c1-ccd6-45df-ed4a-8eed97324bb1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-25 14:27:15.220 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.224 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.225 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.226 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.227 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.227 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.231 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.233 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.233 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.234 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.234 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.234 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.235 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.235 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.236 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.239 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.239 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.240 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.240 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.241 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.241 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.243 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.243 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.244 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.245 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.245 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.247 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.248 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.248 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.250 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.250 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.251 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.252 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.256 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.256 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.257 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.257 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.258 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.258 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.261 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.261 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.262 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.262 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.263 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.263 Session state does not function when running a script without `streamlit run`\n",
            "2025-07-25 14:27:15.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.270 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.270 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.271 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.272 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.272 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.272 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.277 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.277 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.278 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.278 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.281 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.281 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.282 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.282 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.283 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.283 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Toutes les dépendances sont installées\n",
            "\n",
            "======================================================================\n",
            "🌍 CLIMATE SENTIMENT AI - VERSION TRAIN/VAL/TEST\n",
            "======================================================================\n",
            "📱 Interface: Streamlit avec graphiques de losses\n",
            "🤖 Modèle: t5-small avec LoRA\n",
            "💾 Device: cuda\n",
            "📊 Splits: Train(6999), Val(1000), Test(2000)\n",
            "🔍 Corpus: 9999 documents indexés\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-25 14:27:15.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.350 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.352 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.352 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.389 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.389 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.419 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.420 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.421 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.422 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.423 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.423 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.428 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.429 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.430 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.430 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.431 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.432 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.433 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.433 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.435 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.436 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.439 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.441 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.442 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.444 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.445 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.446 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.446 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.447 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.447 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.449 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.450 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.451 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.451 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.452 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.453 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.455 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.456 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.456 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.457 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.458 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.459 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.459 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.460 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.461 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.463 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.465 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.465 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.467 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.467 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.470 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.473 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.474 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.474 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.475 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.475 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.476 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.480 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.480 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.482 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.482 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.483 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.483 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.485 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.486 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.486 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.487 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.487 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.490 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.490 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.491 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.491 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.492 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.493 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.493 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.494 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.494 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.495 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.495 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.496 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.496 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.497 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.497 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.498 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.498 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.499 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.499 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.500 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.500 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.501 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.501 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.502 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.502 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.508 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.513 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.513 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.515 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.515 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.516 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.525 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.525 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.527 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.527 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-25 14:27:15.533 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# 16. INSTRUCTIONS DE DÉPLOIEMENT MISES À JOUR\n",
        "# ====================================================================\n",
        "\n",
        "\"\"\"\n",
        "INSTRUCTIONS DE DÉPLOIEMENT - VERSION TRAIN/VAL/TEST:\n",
        "\n",
        "1. **Installation des dépendances:**\n",
        "   ```bash\n",
        "   pip install streamlit wandb torch transformers peft faiss-cpu sentence-transformers rouge-score plotly pandas numpy tqdm scikit-learn matplotlib\n",
        "   ```\n",
        "\n",
        "2. **Configuration W&B:**\n",
        "   ```bash\n",
        "   export WANDB_API_KEY=\"votre_clé_api_wandb\"\n",
        "   ```\n",
        "\n",
        "3. **Préparation des données:**\n",
        "   - Placez 'sentiment_enriched_data_batch.csv' dans le répertoire\n",
        "   - Le script créera automatiquement les splits 70/10/20\n",
        "\n",
        "4. **Lancement:**\n",
        "   ```bash\n",
        "   streamlit run votre_script.py\n",
        "   ```\n",
        "\n",
        "5. **Nouvelles fonctionnalités:**\n",
        "   - 📈 Graphiques interactifs train/val/test losses\n",
        "   - 📊 Analyse automatique d'overfitting\n",
        "   - 📋 Rapports d'entraînement détaillés\n",
        "   - 🔍 Évaluation par split\n",
        "   - 📉 Métriques de convergence\n",
        "\n",
        "6. **Workflow recommandé:**\n",
        "   - Vérifiez la distribution des données (onglet Analyse)\n",
        "   - Lancez l'entraînement (sidebar)\n",
        "   - Surveillez les losses en temps réel (onglet Losses)\n",
        "   - Analysez l'overfitting (sidebar avancé)\n",
        "   - Évaluez sur le test set final\n",
        "\n",
        "La version inclut un tracking complet des métriques avec détection\n",
        "automatique des problèmes d'entraînement et recommandations.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "TNyAuv8QzBOY",
        "outputId": "d59df954-07a7-4821-e5a1-1c9137062037"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nINSTRUCTIONS DE DÉPLOIEMENT - VERSION TRAIN/VAL/TEST:\\n\\n1. **Installation des dépendances:**\\n   ```bash\\n   pip install streamlit wandb torch transformers peft faiss-cpu sentence-transformers rouge-score plotly pandas numpy tqdm scikit-learn matplotlib\\n   ```\\n\\n2. **Configuration W&B:**\\n   ```bash\\n   export WANDB_API_KEY=\"votre_clé_api_wandb\"\\n   ```\\n\\n3. **Préparation des données:**\\n   - Placez \\'sentiment_enriched_data_batch.csv\\' dans le répertoire\\n   - Le script créera automatiquement les splits 70/10/20\\n\\n4. **Lancement:**\\n   ```bash\\n   streamlit run votre_script.py\\n   ```\\n\\n5. **Nouvelles fonctionnalités:**\\n   - 📈 Graphiques interactifs train/val/test losses\\n   - 📊 Analyse automatique d\\'overfitting\\n   - 📋 Rapports d\\'entraînement détaillés\\n   - 🔍 Évaluation par split\\n   - 📉 Métriques de convergence\\n\\n6. **Workflow recommandé:**\\n   - Vérifiez la distribution des données (onglet Analyse)\\n   - Lancez l\\'entraînement (sidebar)\\n   - Surveillez les losses en temps réel (onglet Losses)\\n   - Analysez l\\'overfitting (sidebar avancé)\\n   - Évaluez sur le test set final\\n\\nLa version inclut un tracking complet des métriques avec détection\\nautomatique des problèmes d\\'entraînement et recommandations.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3c61fcd"
      },
      "source": [],
      "execution_count": 18,
      "outputs": []
    }
  ]
}